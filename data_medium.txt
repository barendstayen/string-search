Parallel computing is a method of performing multiple computations concurrently. It is especially useful for tasks that involve large datasets or repetitive operations. String search is a common example of a problem that can benefit from parallelization. In a naive sequential approach, the search scans the text from beginning to end, checking each possible position. This is simple but slow when the input text is very large.

When we have a many-core CPU, such as modern processors with 6, 8, 12 or more cores, we can divide the workload among different CPU cores. Each core can process a separate section of the text. However, if we simply cut the text into equal partitions, we introduce a boundary problem. Suppose the input pattern begins at the last few characters of one chunk and ends in the next chunk. If the search algorithm scans each chunk independently without overlap, this match will be missed.

To solve this, we introduce overlap. Each worker searches a slightly larger region than its assigned chunk. Specifically, if the pattern length is m, then we extend the text slice by m-1 characters at both ends. When the worker finds matches, it only keeps those that fall within its own actual chunk boundaries. This ensures correctness and prevents duplicate results.

Python provides tools for parallel processing using modules such as multiprocessing or concurrent.futures. Since Python has a Global Interpreter Lock (GIL), using threads for CPU-bound tasks is not efficient. Processes bypass the GIL and allow true parallel computation. Therefore, this project uses ProcessPoolExecutor to distribute work across CPU cores. In addition to the parallel implementation, we include a baseline sequential version to measure performance differences.

The experiment includes three datasets: small, medium, and large. The small dataset tests functional correctness and boundary handling. The medium dataset allows us to test performance without requiring extremely long runtimes. The large dataset tests scalability and demonstrates whether additional cores provide speedup. We will measure the runtime with different worker counts, such as 1, 2, 4, and 8. Results will be recorded in a CSV file. The student will use this data to create graphs showing time versus number of workers and speedup versus number of workers.

Parallelization does not always make the program faster. When the dataset is small, the overhead of creating worker processes and dividing tasks can be greater than the time saved. When the dataset is large, parallelization becomes beneficial. The goal of this assignment is to analyze when parallel search gives an advantage and explain why this happens. The student will provide a report explaining the findings.

This medium dataset ends here. It is structured using repeated concepts so that patterns occur many times throughout the text. This makes it easier to test correctness and evaluate how the algorithm handles boundary crossing, chunk division, and pattern matching.
